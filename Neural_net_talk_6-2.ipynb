{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Nets: The Devil's in the Details\n",
    "\n",
    "Seth Weidman    \n",
    "\n",
    "06/02/2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Nets: WTF is going on??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src='neural_net_wtf.png' height=200>\n",
    "\n",
    "What does this actually mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Review from last time (Pt. 1)\n",
    "\n",
    "* Neural nets are nested functions, where the functions applied to the inputs alternate between two types:\n",
    "    * Linear functions, represented by matrix multiplications\n",
    "    * Non linear \"activation\" functions\n",
    "* Because they are functions, we can represent the neural net making a prediction mathematically. For example, if $X$ is the input, then the prediction $P$ is just: \n",
    "\n",
    "$$ P = A(B(C(D(X, V)), W)) $$\n",
    "\n",
    "where $A$, $B$, $C$, and $D$ are functions and $V$ and $W$ are weight matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Review from last time (Pt. 2)\n",
    "\n",
    "* This prediction is compared to the actual value we were trying to predict, $Y$, and a loss is computed, for example:\n",
    "\n",
    "$$ L = (Y - P) ^ 2 $$\n",
    "\n",
    "* And then the weights are adjusted so that this loss will be reduced:\n",
    "\n",
    "$$ W - \\frac{\\partial L}{\\partial W}$$\n",
    "\n",
    "$$ V - \\frac{\\partial L}{\\partial V}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Key point from last time\n",
    "\n",
    "* This process - of computing derivatives to continually update the weights in a neural net - works because of **the chain rule from calculus**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## We can do basic neural nets!\n",
    "\n",
    "<img src=\"neural_net_check.png\" height=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# This basic neural net framework can learn MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**This basic neural net framework can learn MNIST**\n",
    "\n",
    "## Pt. 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**This basic neural net framework can learn MNIST**\n",
    "\n",
    "## Pt. 2: Read in the MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Read in the MNIST Data\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_mnist_X_Y(mnist):\n",
    "    data = mnist.data\n",
    "    X = (data - data.min()) * 1.0 / (data.max() - data.min())\n",
    "    target = mnist.target\n",
    "    Y = np.zeros((len(target), 10))\n",
    "    for i in range(len(target)):\n",
    "        Y[i][int(target[i])] = 1 \n",
    "    print(\"Number of images: \", X.shape[0])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images:  70000\n"
     ]
    }
   ],
   "source": [
    "X, Y = get_mnist_X_Y(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_prop = 0.9\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, \n",
    "    test_size=1-train_prop, \n",
    "    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**This basic neural net framework can learn MNIST**\n",
    "\n",
    "## Pt. 3: Visualize the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_image(index):\n",
    "    target = mnist.target\n",
    "    print(\"Label: \", int(target[index]))\n",
    "    plt.imshow(1.0 - X[index].reshape(28,28), cmap='gray')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0ERfiCo/wfKBnT2y+G31wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ea64ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_image(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**This basic neural net framework can learn MNIST**\n",
    "\n",
    "## Pt. 4: Train the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def _sigmoid(x):\n",
    "    return 1.0/(1.0+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def learn(X, Y, num_iter):\n",
    "    np.random.seed(2)\n",
    "    V = np.random.randn(784, 50)\n",
    "    W = np.random.randn(50, 10)\n",
    "    for j in range(num_iter):\n",
    "        i = np.random.randint(0, num_iter)\n",
    "        x = np.array(X[i], ndmin=2)\n",
    "        y = np.array(Y[i], ndmin=2)\n",
    "        A = np.dot(x,V)\n",
    "        B = _sigmoid(A)\n",
    "        C = np.dot(B,W)\n",
    "        P = _sigmoid(C)\n",
    "        sum_P = np.sum(P)\n",
    "        L = 0.5 * (y - P) ** 2\n",
    "        dLdP = -1.0 * (y-P)\n",
    "        dPdC = _sigmoid(C) * (1-_sigmoid(C))\n",
    "        dLdC = dLdP * dPdC\n",
    "        dCdW = B.T\n",
    "        dLdW = np.dot(dCdW, dLdC)\n",
    "        dCdB = W.T\n",
    "        dLdB = np.dot(dLdC, dCdB)\n",
    "        dBdA = _sigmoid(A) * (1-_sigmoid(A))\n",
    "        dLdA = dLdB * dBdA\n",
    "        dAdV = x.T\n",
    "        dLdV = np.dot(dAdV, dLdA)\n",
    "        W -= dLdW\n",
    "        V -= dLdV\n",
    "    return V, W  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def predict(X, V, W):\n",
    "    A = np.dot(X,V)\n",
    "    B = _sigmoid(A)\n",
    "    C = np.dot(B,W)\n",
    "    P = _sigmoid(C)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "V, W = learn(X_train, Y_train, num_iter=X_train.shape[0])\n",
    "P = predict(X_test, V, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Net MNIST Classification Accuracy: 91.3 percent\n"
     ]
    }
   ],
   "source": [
    "preds = [np.argmax(x) for x in P]\n",
    "actuals = [np.argmax(x) for x in Y_test]\n",
    "\n",
    "accuracy = sum(np.array(preds) == np.array(actuals)) * 1.0 / len(preds)\n",
    "print(\"Neural Net MNIST Classification Accuracy:\", round(accuracy, 3) * 100, \"percent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Good..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "...but not optimal: [see here](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html)\n",
    "\n",
    "<img src='MNIST_performance.png' height=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How can we do better?\n",
    "\n",
    "Our options include:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Building deeper nets\n",
    "* Changing \"learning rates\" / using \"learning rate decay\"\n",
    "* Changing \"weight initialization\"\n",
    "* Adding \"dropout\"\n",
    "* ...and that doesn't even cover many of the cutting edge techniques listed above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Are you overwhelmed yet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Paradox of choice\n",
    "\n",
    "<img src=\"supermarket.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Neural nets are really hard to unpack and understand - so much so that a lot of people don't even try.\n",
    "\n",
    "**By \"playing with these knobs\" individually - as well as learning a bit of theory, we can \"peek under the hood\" and understand how neural nets are working.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multiple hidden layers (\"Deep Learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**\"What I cannot build, I cannot understand.\"**\n",
    "\n",
    "--Richard Feynman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Before:\n",
    "\n",
    "With a neural net with one hidden layer, one pass through was 25 manually coded steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "_This will quickly get unweildy if we add more hidden layers._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## New understanding: \"Layers\"\n",
    "\n",
    "No longer will we think of neural nets as complicated mathematical functions like $ P = A(B(C(D(X, V)), W)) $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### New understanding: \"Layers\"\n",
    "\n",
    "Instead, we'll think of them as a series of layers:\n",
    "\n",
    "<img src='neural_net_layers.png' height=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Coding the new neural network, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We'll define a `NeuralNetwork` class that defines a neural network as a series of `Layers`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers, random_seed):\n",
    "        self.layers = layers\n",
    "        self.random_seed = random_seed\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            setattr(layer, 'random_seed', self.random_seed+i)\n",
    "            layer.initialize_weights()\n",
    "\n",
    "\n",
    "    def forwardpass(self, X):\n",
    "        \"\"\" Calculate an output Y for the given input X. \"\"\"\n",
    "        X_next = X\n",
    "        for layer in self.layers:\n",
    "            X_next = layer.fprop(X_next)\n",
    "        prediction = X_next\n",
    "        return prediction\n",
    "\n",
    "    def loss(self, prediction, Y):\n",
    "        \"\"\" Calculate error on the given data. \"\"\"\n",
    "        loss = 0.5 * (Y - prediction) ** 2\n",
    "        return -1.0 * (Y - prediction)\n",
    "\n",
    "    def backpropogate(self, loss):\n",
    "        \"\"\" Calculate an output Y for the given input X. \"\"\"\n",
    "        loss_next = loss\n",
    "        for layer in reversed(self.layers):\n",
    "            loss_next = layer.bprop(loss_next)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Coding the new neural network, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    def _setup(self, input_shape):\n",
    "        \"\"\" Setup layer with parameters that are unknown at __init__(). \"\"\"\n",
    "        pass\n",
    "\n",
    "    def fprop(self, input):\n",
    "        \"\"\" Calculate layer output for given input (forward propagation). \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def bprop(self, output_grad):\n",
    "        \"\"\" Calculate input gradient. \"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Coding the new neural network, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class Linear(Layer):\n",
    "    \n",
    "    random_seed = None\n",
    "    \n",
    "    def __init__(self, n_in, n_out, \n",
    "                 activation_function):\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out        \n",
    "        self.iteration = None\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        np.random.seed(seed=self.random_seed)\n",
    "        self.W = np.random.normal(size=(self.n_in, self.n_out))\n",
    "\n",
    "    def fprop(self, layer_input):\n",
    "        self.layer_input = layer_input\n",
    "        self.activation_input = np.dot(layer_input, self.W)\n",
    "        return self.activation_function(self.activation_input, bprop=False)\n",
    "\n",
    "    def bprop(self, layer_gradient):\n",
    "        dOutdActivationInput = self.activation_function(self.activation_input, bprop=True)\n",
    "        dLayerInputdActivationInput = layer_gradient * dOutdActivationInput\n",
    "        dActivationOutputdActivationInput = self.layer_input.T\n",
    "        output_grad = np.dot(dLayerInputdActivationInput, self.W.T)\n",
    "        W_new = self.W - np.dot(dActivationOutputdActivationInput, dLayerInputdActivationInput)\n",
    "        self.W = W_new\n",
    "        return output_grad\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Coding the new neural network, layers - and don't forget about that activation function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x, bprop=False):\n",
    "    if bprop:\n",
    "        s = sigmoid(x)\n",
    "        return s*(1-s)\n",
    "    else:\n",
    "        return 1.0/(1.0+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Running this neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "layer1 = Linear(n_in=784, n_out=50, activation_function=sigmoid)\n",
    "layer2 = Linear(n_in=50, n_out=10, activation_function=sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nn_mnist = NeuralNetwork(\n",
    "    layers=[layer1, layer2],\n",
    "    random_seed=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def neural_net_pass(net, x, y):\n",
    "    pred = net.forwardpass(x)\n",
    "    loss = net.loss(pred, y)\n",
    "    net.backpropogate(loss)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Running this neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Randomly shuffle the indices of the points in the training set:\n",
    "np.random.seed(4)\n",
    "data_size = X.shape[0]\n",
    "train_size = int(train_prop * data_size)\n",
    "indices = list(range(train_size))\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Loop through every element in the training set: \n",
    "for index in indices:\n",
    "    x = np.array(X_train[index], ndmin=2)\n",
    "    y = np.array(Y_train[index], ndmin=2)\n",
    "    neural_net_pass(nn_mnist, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "P = nn_mnist.forwardpass(X_test)\n",
    "preds = [np.argmax(x) for x in P]\n",
    "actuals = [np.argmax(x) for x in Y_test]\n",
    "\n",
    "accuracy = sum(np.array(preds) == np.array(actuals)) * 1.0 / len(preds)\n",
    "print(\"Neural Net MNIST Classification Accuracy:\", round(accuracy, 3) * 100, \"percent\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A different random weight initialization gave us just 82.3% accuracy this time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Learning rate momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Weight initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dropout"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "47px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
